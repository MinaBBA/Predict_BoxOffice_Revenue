{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import json\n",
    "import ast\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "# from import lightgbm\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read train and test datasets, change the json-like columns to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 23 columns):\n",
      "id                       3000 non-null int64\n",
      "belongs_to_collection    604 non-null object\n",
      "budget                   3000 non-null int64\n",
      "genres                   2993 non-null object\n",
      "homepage                 946 non-null object\n",
      "imdb_id                  3000 non-null object\n",
      "original_language        3000 non-null object\n",
      "original_title           3000 non-null object\n",
      "overview                 2992 non-null object\n",
      "popularity               3000 non-null float64\n",
      "poster_path              2999 non-null object\n",
      "production_companies     2844 non-null object\n",
      "production_countries     2945 non-null object\n",
      "release_date             3000 non-null object\n",
      "runtime                  2998 non-null float64\n",
      "spoken_languages         2980 non-null object\n",
      "status                   3000 non-null object\n",
      "tagline                  2403 non-null object\n",
      "title                    3000 non-null object\n",
      "Keywords                 2724 non-null object\n",
      "cast                     2987 non-null object\n",
      "crew                     2984 non-null object\n",
      "revenue                  3000 non-null int64\n",
      "dtypes: float64(2), int64(3), object(18)\n",
      "memory usage: 539.1+ KB\n"
     ]
    }
   ],
   "source": [
    "train= pd.read_csv('train.csv')\n",
    "test= pd.read_csv('test.csv')\n",
    "\n",
    "#manually correct some of the budget values in both train and test\n",
    "\n",
    "train.loc[train['id'] == 16,'revenue'] = 192864          # Skinning\n",
    "train.loc[train['id'] == 90,'budget'] = 30000000         # Sommersby          \n",
    "train.loc[train['id'] == 118,'budget'] = 60000000        # Wild Hogs\n",
    "train.loc[train['id'] == 149,'budget'] = 18000000        # Beethoven\n",
    "train.loc[train['id'] == 313,'revenue'] = 12000000       # The Cookout \n",
    "train.loc[train['id'] == 451,'revenue'] = 12000000       # Chasing Liberty\n",
    "train.loc[train['id'] == 464,'budget'] = 20000000        # Parenthood\n",
    "train.loc[train['id'] == 470,'budget'] = 13000000        # The Karate Kid, Part II\n",
    "train.loc[train['id'] == 513,'budget'] = 930000          # From Prada to Nada\n",
    "train.loc[train['id'] == 797,'budget'] = 8000000         # Welcome to Dongmakgol\n",
    "train.loc[train['id'] == 819,'budget'] = 90000000        # Alvin and the Chipmunks: The Road Chip\n",
    "train.loc[train['id'] == 850,'budget'] = 90000000        # Modern Times\n",
    "train.loc[train['id'] == 1007,'budget'] = 2              # Zyzzyx Road \n",
    "train.loc[train['id'] == 1112,'budget'] = 7500000        # An Officer and a Gentleman\n",
    "train.loc[train['id'] == 1131,'budget'] = 4300000        # Smokey and the Bandit   \n",
    "train.loc[train['id'] == 1359,'budget'] = 10000000       # Stir Crazy \n",
    "train.loc[train['id'] == 1542,'budget'] = 1              # All at Once\n",
    "train.loc[train['id'] == 1570,'budget'] = 15800000       # Crocodile Dundee II\n",
    "train.loc[train['id'] == 1571,'budget'] = 4000000        # Lady and the Tramp\n",
    "train.loc[train['id'] == 1714,'budget'] = 46000000       # The Recruit\n",
    "train.loc[train['id'] == 1721,'budget'] = 17500000       # Cocoon\n",
    "train.loc[train['id'] == 1865,'revenue'] = 25000000      # Scooby-Doo 2: Monsters Unleashed\n",
    "train.loc[train['id'] == 1885,'budget'] = 12             # In the Cut\n",
    "train.loc[train['id'] == 2091,'budget'] = 10             # Deadfall\n",
    "train.loc[train['id'] == 2268,'budget'] = 17500000       # Madea Goes to Jail budget\n",
    "train.loc[train['id'] == 2491,'budget'] = 6              # Never Talk to Strangers\n",
    "train.loc[train['id'] == 2602,'budget'] = 31000000       # Mr. Holland's Opus\n",
    "train.loc[train['id'] == 2612,'budget'] = 15000000       # Field of Dreams\n",
    "train.loc[train['id'] == 2696,'budget'] = 10000000       # Nurse 3-D\n",
    "train.loc[train['id'] == 2801,'budget'] = 10000000       # Fracture\n",
    "train.loc[train['id'] == 335,'budget'] = 2 \n",
    "train.loc[train['id'] == 348,'budget'] = 12\n",
    "train.loc[train['id'] == 470,'budget'] = 13000000 \n",
    "train.loc[train['id'] == 513,'budget'] = 1100000\n",
    "train.loc[train['id'] == 640,'budget'] = 6 \n",
    "train.loc[train['id'] == 696,'budget'] = 1\n",
    "train.loc[train['id'] == 797,'budget'] = 8000000 \n",
    "train.loc[train['id'] == 850,'budget'] = 1500000\n",
    "train.loc[train['id'] == 1199,'budget'] = 5 \n",
    "train.loc[train['id'] == 1282,'budget'] = 9               # Death at a Funeral\n",
    "train.loc[train['id'] == 1347,'budget'] = 1\n",
    "train.loc[train['id'] == 1755,'budget'] = 2\n",
    "train.loc[train['id'] == 1801,'budget'] = 5\n",
    "train.loc[train['id'] == 1918,'budget'] = 592 \n",
    "train.loc[train['id'] == 2033,'budget'] = 4\n",
    "train.loc[train['id'] == 2118,'budget'] = 344 \n",
    "train.loc[train['id'] == 2252,'budget'] = 130\n",
    "train.loc[train['id'] == 2256,'budget'] = 1 \n",
    "train.loc[train['id'] == 2696,'budget'] = 10000000\n",
    "\n",
    "#=====================================================================\n",
    "\n",
    "#Clean Data test\n",
    "test.loc[test['id'] == 6733,'budget'] = 5000000\n",
    "test.loc[test['id'] == 3889,'budget'] = 15000000\n",
    "test.loc[test['id'] == 6683,'budget'] = 50000000\n",
    "test.loc[test['id'] == 5704,'budget'] = 4300000\n",
    "test.loc[test['id'] == 6109,'budget'] = 281756\n",
    "test.loc[test['id'] == 7242,'budget'] = 10000000\n",
    "test.loc[test['id'] == 7021,'budget'] = 17540562       #  Two Is a Family\n",
    "test.loc[test['id'] == 5591,'budget'] = 4000000        # The Orphanage\n",
    "test.loc[test['id'] == 4282,'budget'] = 20000000       # Big Top Pee-wee\n",
    "test.loc[test['id'] == 3033,'budget'] = 250 \n",
    "test.loc[test['id'] == 3051,'budget'] = 50\n",
    "test.loc[test['id'] == 3084,'budget'] = 337\n",
    "test.loc[test['id'] == 3224,'budget'] = 4  \n",
    "test.loc[test['id'] == 3594,'budget'] = 25  \n",
    "test.loc[test['id'] == 3619,'budget'] = 500  \n",
    "test.loc[test['id'] == 3831,'budget'] = 3  \n",
    "test.loc[test['id'] == 3935,'budget'] = 500  \n",
    "test.loc[test['id'] == 4049,'budget'] = 995946 \n",
    "test.loc[test['id'] == 4424,'budget'] = 3  \n",
    "test.loc[test['id'] == 4460,'budget'] = 8  \n",
    "test.loc[test['id'] == 4555,'budget'] = 1200000 \n",
    "test.loc[test['id'] == 4624,'budget'] = 30 \n",
    "test.loc[test['id'] == 4645,'budget'] = 500 \n",
    "test.loc[test['id'] == 4709,'budget'] = 450 \n",
    "test.loc[test['id'] == 4839,'budget'] = 7\n",
    "test.loc[test['id'] == 3125,'budget'] = 25 \n",
    "test.loc[test['id'] == 3142,'budget'] = 1\n",
    "test.loc[test['id'] == 3201,'budget'] = 450\n",
    "test.loc[test['id'] == 3222,'budget'] = 6\n",
    "test.loc[test['id'] == 3545,'budget'] = 38\n",
    "test.loc[test['id'] == 3670,'budget'] = 18\n",
    "test.loc[test['id'] == 3792,'budget'] = 19\n",
    "test.loc[test['id'] == 3881,'budget'] = 7\n",
    "test.loc[test['id'] == 3969,'budget'] = 400\n",
    "test.loc[test['id'] == 4196,'budget'] = 6\n",
    "test.loc[test['id'] == 4221,'budget'] = 11\n",
    "test.loc[test['id'] == 4222,'budget'] = 500\n",
    "test.loc[test['id'] == 4285,'budget'] = 11\n",
    "test.loc[test['id'] == 4319,'budget'] = 1\n",
    "test.loc[test['id'] == 4639,'budget'] = 10\n",
    "test.loc[test['id'] == 4719,'budget'] = 45\n",
    "test.loc[test['id'] == 4822,'budget'] = 22\n",
    "test.loc[test['id'] == 4829,'budget'] = 20\n",
    "test.loc[test['id'] == 4969,'budget'] = 20\n",
    "test.loc[test['id'] == 5021,'budget'] = 40 \n",
    "test.loc[test['id'] == 5035,'budget'] = 1 \n",
    "test.loc[test['id'] == 5063,'budget'] = 14 \n",
    "test.loc[test['id'] == 5119,'budget'] = 2 \n",
    "test.loc[test['id'] == 5214,'budget'] = 30 \n",
    "test.loc[test['id'] == 5221,'budget'] = 50 \n",
    "test.loc[test['id'] == 4903,'budget'] = 15\n",
    "test.loc[test['id'] == 4983,'budget'] = 3\n",
    "test.loc[test['id'] == 5102,'budget'] = 28\n",
    "test.loc[test['id'] == 5217,'budget'] = 75\n",
    "test.loc[test['id'] == 5224,'budget'] = 3 \n",
    "test.loc[test['id'] == 5469,'budget'] = 20 \n",
    "test.loc[test['id'] == 5840,'budget'] = 1 \n",
    "test.loc[test['id'] == 5960,'budget'] = 30\n",
    "test.loc[test['id'] == 6506,'budget'] = 11 \n",
    "test.loc[test['id'] == 6553,'budget'] = 280\n",
    "test.loc[test['id'] == 6561,'budget'] = 7\n",
    "test.loc[test['id'] == 6582,'budget'] = 218\n",
    "test.loc[test['id'] == 6638,'budget'] = 5\n",
    "test.loc[test['id'] == 6749,'budget'] = 8 \n",
    "test.loc[test['id'] == 6759,'budget'] = 50 \n",
    "test.loc[test['id'] == 6856,'budget'] = 10\n",
    "test.loc[test['id'] == 6858,'budget'] =  100\n",
    "test.loc[test['id'] == 6876,'budget'] =  250\n",
    "test.loc[test['id'] == 6972,'budget'] = 1\n",
    "test.loc[test['id'] == 7079,'budget'] = 8000000\n",
    "test.loc[test['id'] == 7150,'budget'] = 118\n",
    "test.loc[test['id'] == 6506,'budget'] = 118\n",
    "test.loc[test['id'] == 7225,'budget'] = 6\n",
    "test.loc[test['id'] == 7231,'budget'] = 85\n",
    "test.loc[test['id'] == 5222,'budget'] = 5\n",
    "test.loc[test['id'] == 5322,'budget'] = 90\n",
    "test.loc[test['id'] == 5350,'budget'] = 70\n",
    "test.loc[test['id'] == 5378,'budget'] = 10\n",
    "test.loc[test['id'] == 5545,'budget'] = 80\n",
    "test.loc[test['id'] == 5810,'budget'] = 8\n",
    "test.loc[test['id'] == 5926,'budget'] = 300\n",
    "test.loc[test['id'] == 5927,'budget'] = 4\n",
    "test.loc[test['id'] == 5986,'budget'] = 1\n",
    "test.loc[test['id'] == 6053,'budget'] = 20\n",
    "test.loc[test['id'] == 6104,'budget'] = 1\n",
    "test.loc[test['id'] == 6130,'budget'] = 30\n",
    "test.loc[test['id'] == 6301,'budget'] = 150\n",
    "test.loc[test['id'] == 6276,'budget'] = 100\n",
    "test.loc[test['id'] == 6473,'budget'] = 100\n",
    "test.loc[test['id'] == 6842,'budget'] = 30\n",
    "\n",
    "\n",
    "test['revenue'] = np.nan\n",
    "\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_list(x):\n",
    "    try:\n",
    "        return ast.literal_eval(x)\n",
    "    except:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add total votes and rating to both train and test \n",
    "# features from https://www.kaggle.com/kamalchhirang/eda-simple-feature-engineering-external-data\n",
    "\n",
    "TrainAdditionalFeatures=pd.read_csv('tmdb-competition-additional-features/TrainAdditionalFeatures.csv')\n",
    "TestAdditionalFeatures=pd.read_csv('tmdb-competition-additional-features/TestAdditionalFeatures.csv')\n",
    "train = pd.merge(train, TrainAdditionalFeatures, how='left', on=['imdb_id'])\n",
    "test = pd.merge(test,TestAdditionalFeatures, how='left', on=['imdb_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add additional data to train\n",
    "# features from https://www.kaggle.com/kamalchhirang/eda-simple-feature-engineering-external-data\n",
    "\n",
    "additionalTrainData = pd.read_csv('tmdb-box-office-prediction-more-training-data/additionalTrainData.csv')\n",
    "additionalTrainData['release_date'] = additionalTrainData['release_date'].astype('str')\n",
    "additionalTrainData['release_date'] = additionalTrainData['release_date'].str.replace('-', '/')\n",
    "train = pd.concat([train, additionalTrainData],ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------\n",
    "#convert type of categorical columns from str to list using str_to_list function\n",
    "columns_to_convert=['genres','production_companies','production_countries',\n",
    "                    'belongs_to_collection','spoken_languages',\n",
    "                     'Keywords', 'cast', 'crew']\n",
    "# convert all the columns with json format, and pass on empty rows \n",
    "for column in columns_to_convert:\n",
    "    try:\n",
    "        train[column]=train[column].apply(str_to_list)\n",
    "        test[column]=test[column].apply(str_to_list)\n",
    "    except:\n",
    "        {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary for the json-like columns to store all the names and their frequency of occurance\n",
    "json_columns=['genres','production_companies','production_countries',\n",
    "        'spoken_languages','Keywords', 'cast', 'crew']\n",
    "\n",
    "def get_names_frequency (df):\n",
    "    global json_columns\n",
    "    df_dict=dict()\n",
    "    \n",
    "    for column in json_columns:\n",
    "        column_dict=dict()\n",
    "        \n",
    "        for row in df[column]:\n",
    "            if row != {}:\n",
    "                for item in row:\n",
    "                    if item['name'] in column_dict.keys():\n",
    "                        column_dict[item['name']] += 1\n",
    "                    else:\n",
    "                        column_dict[item['name']] = 1   \n",
    "\n",
    "        df_dict[column]=column_dict\n",
    "    return df_dict   \n",
    "        \n",
    "train_names=get_names_frequency(train)   \n",
    "test_names=get_names_frequency(test)\n",
    "\n",
    "# train_names and test_names are both dictionaries of dictionaries.\n",
    "# for each column of train and test, keep the names that exist in both datasets\n",
    "# delete names with frequency <10 in the train_names\n",
    "# print(len(train_names['production_companies']))\n",
    "\n",
    "for column in json_columns:\n",
    "    remove_names=[]\n",
    "    train_names_keys=set(list(train_names[column].keys())) # returns a dict\n",
    "    test_names_keys=set(list(test_names[column].keys()))\n",
    "    \n",
    "    names_to_remove=list(train_names_keys-test_names_keys)+list(test_names_keys-train_names_keys)\n",
    "\n",
    "    for name in names_to_remove:\n",
    "        if name in train_names[column]:\n",
    "            del train_names[column][name]\n",
    "        if name in test_names[column]:\n",
    "            del test_names[column][name] \n",
    "\n",
    "    for name in train_names_keys:\n",
    "        if name not in names_to_remove:\n",
    "            if train_names[column][name] < 10:\n",
    "                del train_names[column][name]           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df=pd.concat([train, test])\n",
    "combined_df.to_csv('combined_df.csv',index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prepare(df):\n",
    "    global train_names\n",
    "    # craete 4 columns for year , quarter, month, and dayof week using release date\n",
    "    df[['release_month','release_day','release_year']]=df['release_date'].\\\n",
    "    str.split('/',expand=True).replace(np.nan, -1).astype(int)\n",
    "    df['release_year']=df['release_year'].apply(lambda x: x+2000 if x<19 else x+1900)\n",
    "    df['release_dayofweek']=pd.to_datetime(df['release_date']).dt.dayofweek\n",
    "    df['release_quarter']=pd.to_datetime(df['release_date']).dt.quarter\n",
    "\n",
    "    # # calculate mean revenue by year, quarter, month, and dayofweek\n",
    "    # for column in ['release_year','release_quarter','release_month','release_dayofweek']:\n",
    "    #     temp_list=df.groupby(column)['revenue'].mean()\n",
    "    #     df['mean_revenue_by_'+column]=df[column].apply(lambda x: temp_list[x])\n",
    "\n",
    "    # # calculate mean budget by year, quarter, month, and dayofweek\n",
    "    # for column in ['release_year','release_quarter','release_month','release_dayofweek']:\n",
    "    #     temp_list=df.groupby(column)['budget'].mean()\n",
    "    #     df['mean_budget_by_'+ column]=df[column].apply(lambda x: temp_list[x])\n",
    "\n",
    "    # #calculate mean runtime , popularity by year\n",
    "    # for i in ['runtime','popularity']:\n",
    "    #     for column in ['release_year']:\n",
    "    #         temp_list=df.groupby(column)[i].mean()\n",
    "    #         df['mean_'+i+'_by_'+ column]=df[column].apply(lambda x: temp_list[x])\n",
    "\n",
    "    #==============\n",
    "    #runtime\n",
    "    df['meanruntimeByYear'] = df.groupby(\"release_year\")[\"runtime\"].transform('mean')\n",
    "\n",
    "    # total votes\n",
    "    df['meantotalVotesByYear'] = df.groupby(\"release_year\")[\"totalVotes\"].transform('mean')\n",
    "    df['meanTotalVotesByRating'] = df.groupby(\"rating\")[\"totalVotes\"].transform('mean')\n",
    "    \n",
    "    #popularity\n",
    "    df['meanPopularityByYear'] = df.groupby(\"release_year\")[\"popularity\"].transform('mean')\n",
    "    df['_popularity_mean_year'] = df['popularity'] / df.groupby(\"release_year\")[\"popularity\"].transform('mean')\n",
    "\n",
    "\n",
    "    #budget: original budget vs inflation budget\n",
    "    df['originalBudget'] = df['budget']\n",
    "    df['meanBudgetByYear'] = df.groupby(\"release_year\")['originalBudget'].transform('mean')\n",
    "    df['medianBudgetByYear'] = df.groupby(\"release_year\")['originalBudget'].transform('median')\n",
    "    \n",
    "    df['inflationBudget'] = df['originalBudget'] + df['originalBudget']*1.8/100*(2018-df['release_year']) #Inflation simple formula\n",
    "    df['budget'] = np.log1p(df['budget'])  #log(1+x)\n",
    "  \n",
    "    #ratios\n",
    "    df['_budget_runtime_ratio'] = df['budget']/df['runtime'] \n",
    "    df['_budget_popularity_ratio'] = df['budget']/df['popularity']\n",
    "    df['_budget_year_ratio'] = df['budget']/(df['release_year'])\n",
    "\n",
    "    df['_releaseYear_popularity_ratio'] = df['release_year']/df['popularity']\n",
    "    df['_releaseYear_popularity_ratio2'] = df['popularity']/df['release_year']\n",
    "\n",
    "    df['_popularity_totalVotes_ratio'] = df['totalVotes']/df['popularity']\n",
    "    df['_rating_popularity_ratio'] = df['rating']/df['popularity']\n",
    "    df['_rating_totalVotes_ratio'] = df['totalVotes']/df['rating']\n",
    "    df['_totalVotes_releaseYear_ratio'] = df['totalVotes']/df['release_year']\n",
    "    df['_budget_rating_ratio'] = df['budget']/df['rating']\n",
    "    df['_runtime_rating_ratio'] = df['runtime']/df['rating']\n",
    "    df['_budget_totalVotes_ratio'] = df['budget']/df['totalVotes']\n",
    "    #=================\n",
    "    \n",
    "    df['has_homepage'] = 1\n",
    "    df.loc[pd.isnull(df['homepage']) ,\"has_homepage\"] = 0  \n",
    "\n",
    "    df['isbelongs_to_collectionNA'] = 0\n",
    "    df.loc[pd.isnull(df['belongs_to_collection']) ,\"isbelongs_to_collectionNA\"] = 1\n",
    "\n",
    "    df['isTaglineNA'] = 0\n",
    "    df.loc[df['tagline'] == 0 ,\"isTaglineNA\"] = 1 \n",
    "\n",
    "    df['isOriginalLanguageEng'] = 0 \n",
    "    df.loc[ df['original_language'] == \"en\" ,\"isOriginalLanguageEng\"] = 1\n",
    "\n",
    "    df['isTitleDifferent'] = 1\n",
    "    df.loc[ df['original_title'] == df['title'] ,\"isTitleDifferent\"] = 0 \n",
    "\n",
    "    df['isMovieReleased'] = 1\n",
    "    df.loc[ df['status'] != \"Released\" ,\"isMovieReleased\"] = 0 \n",
    "    \n",
    "    #=================  \n",
    "    df['original_title_letter_count'] = df['original_title'].str.len() \n",
    "    df['original_title_word_count'] = df['original_title'].str.split().str.len() \n",
    "    df['title_word_count'] = df['title'].str.split().str.len()\n",
    "    df['overview_word_count'] = df['overview'].str.split().str.len()\n",
    "    df['tagline_word_count'] = df['tagline'].str.split().str.len()\n",
    "    \n",
    "    df['_num_Keywords'] = df['Keywords'].apply(lambda x: len(x) if x != {} else 0)\n",
    "    df['_num_production_companies'] = df['production_companies'].apply(lambda x: len(x) if x != {} else 0) \n",
    "    df['_num_cast'] = df['cast'].apply(lambda x: len(x) if x != {} else 0) \n",
    "    df['_num_crew'] = df['crew'].apply(lambda x: len(x) if x != {} else 0) \n",
    "\n",
    "    #=================   \n",
    "    #number of genders in cast and crew\n",
    "    def count_by_key_value(row,key,value):\n",
    "        c=0\n",
    "        try:\n",
    "            for dic in row:\n",
    "                if dic[key] == value:\n",
    "                    c+= 1\n",
    "        except: \n",
    "            pass   \n",
    "        return c\n",
    "    \n",
    "    for i in [0,1,2]:\n",
    "        df['_num_'+str(i)+'_gender_cast']=df['cast'].apply(lambda x: count_by_key_value(x,'gender',i) )    \n",
    "        df['_num_'+str(i)+'_gender_crew']=df['crew'].apply(lambda x: count_by_key_value(x,'gender',i) )\n",
    "\n",
    "    #=================     \n",
    "    \n",
    "    df['_collection_name'] = df['belongs_to_collection'].apply(lambda x: x[0]['name'] if x != {} else 0)\n",
    "    le = LabelEncoder()\n",
    "    le.fit(list(df['_collection_name'].fillna('')))\n",
    "    df['_collection_name'] = le.transform(df['_collection_name'].fillna('').astype(str))\n",
    "    \n",
    "\n",
    "    # get collection id   ===========================\n",
    "    df['collection_id'] = df['belongs_to_collection'].\\\n",
    "                        apply(lambda x : np.nan if len(x)==0 else x[0]['id'])\n",
    "\n",
    "\n",
    "    \n",
    "    for col in ['genres', 'production_countries', 'spoken_languages', 'production_companies'] :\n",
    "        df[col] = df[col].map(lambda x: sorted(list(set([n if n in train_names[col] else col+'_etc' for n in [d['name'] for d in x]])))).map(lambda x: ','.join(map(str, x)))\n",
    "        temp = df[col].str.get_dummies(sep=',')\n",
    "        df = pd.concat([df, temp], axis=1, sort=False)\n",
    "    df.drop(['genres_etc'], axis = 1, inplace = True)\n",
    "\n",
    "    df = df.drop(['id', 'revenue','belongs_to_collection','genres','homepage','imdb_id','overview','runtime'\n",
    "        ,'poster_path','production_companies','production_countries','release_date','spoken_languages'\n",
    "        ,'status','title','Keywords','cast','crew','original_language','original_title','tagline', 'collection_id'\n",
    "        ],axis=1)\n",
    "\n",
    "    df.fillna(value=0.0, inplace = True) \n",
    "\n",
    "    return df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = prepare(combined_df.reset_index(drop = True))\n",
    "all_data2=all_data.copy()\n",
    "all_data2=all_data2.drop(columns=['_budget_totalVotes_ratio','_budget_rating_ratio',\n",
    "                       '_budget_runtime_ratio','_rating_totalVotes_ratio',\n",
    "                       '_runtime_rating_ratio'])\n",
    "\n",
    "train2 = all_data2.loc[:train.shape[0] - 1,:]\n",
    "test2 = all_data2.loc[train.shape[0]:,:]\n",
    "y=np.power(train['revenue'].values,1/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-31243d218547>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_samples_leaf\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m199\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train Set'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"(\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "#best results were: \n",
    " #   max_features = n_features\n",
    " #   min_samples_leaf = 5\n",
    " #   num_trees = 1000 \n",
    "X_train, X_test,y_train, y_test = train_test_split(train2,y,test_size = 0.33,random_state=12)\n",
    "\n",
    "model=RandomForestRegressor(n_estimators=1000,min_samples_leaf =5,max_features=199)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "print('Train Set',str(model).split(\"(\")[0],model.score(X_train,y_train))\n",
    "print('Test Set',str(model).split(\"(\")[0],model.score(X_test,y_test))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set RandomForestRegressor 0.8991264719261629\n",
      "Test Set RandomForestRegressor 0.7357466531377658\n"
     ]
    }
   ],
   "source": [
    "print('Train Set',str(model).split(\"(\")[0],model.score(X_train,y_train))\n",
    "print('Test Set',str(model).split(\"(\")[0],model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /Users/minabba/.kaggle/kaggle.json'\n",
      "100%|████████████████████████████████████████| 100k/100k [00:03<00:00, 27.1kB/s]\n",
      "Successfully submitted to TMDB Box Office Prediction"
     ]
    }
   ],
   "source": [
    "test['revenue'] = model.predict(test2)\n",
    "test['revenue']=test['revenue'].apply(lambda x: np.power(x,6))\n",
    "test[['id','revenue']].to_csv('test_submission.csv',index = False, header = True)\n",
    "!kaggle competitions submit -f 'test_submission.csv' -m 'rnf-all' tmdb-box-office-prediction\n",
    "test=test.drop(columns=['revenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_scale=[]\n",
    "for column in all_data2.columns:\n",
    "    if all_data2[column].max() >1:\n",
    "          columns_to_scale.append(column)\n",
    "    \n",
    "for column in columns_to_scale: \n",
    "    try:\n",
    "        scaler = MinMaxScaler()\n",
    "        fitted = scaler.fit(all_data2[column].values.reshape(-1,1))\n",
    "        all_data2[column] = fitted.transform(all_data2[column].values.reshape(-1,1))\n",
    "    except:\n",
    "        print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data2=all_data2.drop(columns=['_budget_totalVotes_ratio','_budget_rating_ratio',\n",
    "                       '_budget_runtime_ratio','_rating_totalVotes_ratio',\n",
    "                       '_runtime_rating_ratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = all_data2.loc[:train.shape[0] - 1,:]\n",
    "test2 = all_data2.loc[train.shape[0]:,:]\n",
    "y=np.log1p(train['revenue']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1-20\n",
    "train2[train2.columns[:20]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test,y_train, y_test = train_test_split(train2,y,test_size = 0.2,random_state=46)\n",
    "nn_model = Sequential()\n",
    "nn_model.add(Dense(units = 30, activation = 'relu',input_dim =(train2.shape)[1]))\n",
    "nn_model.add(Dense(units = 30, activation = 'relu'))\n",
    "nn_model.add(Dense(units = 1, activation = 'linear'))\n",
    "nn_model.compile(loss = 'mean_squared_error',optimizer = 'adam',metrics = ['mean_squared_error'])\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model.fit(X_train,y_train,epochs = 300,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for model in [linear_model.LinearRegression(),\n",
    "              linear_model.Lasso(alpha=0.1),\n",
    "              RandomForestRegressor(n_estimators=500),\n",
    "              GradientBoostingRegressor(),\n",
    "              KNeighborsRegressor(n_neighbors=6)\n",
    "             ]:\n",
    "    model.fit(X_train,y_train)\n",
    "    models.append(model)\n",
    "    \n",
    "    print('Train Set',str(model).split(\"(\")[0],model.score(X_train,y_train))\n",
    "    print('Test Set',str(model).split(\"(\")[0],model.score(X_test,y_test))\n",
    "    print(mean_squared_error(y_test,model.predict(X_test)),r2_score(y_test,model.predict(X_test)))\n",
    "    print('-'*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "dtrain = xgb.DMatrix(all_data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test,y_train, y_test = train_test_split(train2,y,test_size = 0.2,random_state=46)\n",
    "\n",
    "\n",
    "\n",
    "param = {'max_depth': 2, 'eta': 1, 'silent': 1, 'objective': 'binary:logistic'}\n",
    "num_round = 10\n",
    "bst = xgb.train(param, dtrain, num_round)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read test data and print its info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mina={'genre':{\"comedy\":10,'drama':12,'horor':5,'romance':8},\\\n",
    "      'country':{'usa':30,'Iran':10,'canada':20}}\n",
    "mj={'genre':{\"comedy\":10,'action':12,'fiction':5,'romance':8},\\\n",
    "      'country':{'usa':30,'UK':10,'canada':20}}\n",
    "if 'comedy' in mina['genre']:\n",
    "    print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mina_genre=mina['genre'].keys()\n",
    "print(sorted(mina_genre))\n",
    "','.join(map(str, sorted(mina_genre)))\n",
    "# mj_genre=set(list(mj['genre'].keys()))\n",
    "# list(mina_genre-mj_genre)+list(mj_genre-mina_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mina_genre.union(mj_genre)-set(list(mina_genre-mj_genre)+list(mj_genre-mina_genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['genres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for col in ['genres', 'production_countries', 'spoken_languages', 'production_companies'] :\n",
    "        df[col] = df[col].map(lambda x: sorted(list(set([n if n in train_dict[col] else col+'_etc' for n in [d['name'] for d in x]])))).map(lambda x: ','.join(map(str, x)))\n",
    "        temp = df[col].str.get_dummies(sep=',')\n",
    "        df = pd.concat([df, temp], axis=1, sort=False)\n",
    "    df.drop(['genres_etc'], axis = 1, inplace = True)\n",
    "    \n",
    "for d in x:    \n",
    "    for n in [d['name'] ]:\n",
    "        if n in train_dict[col]:\n",
    "            n\n",
    "        else:\n",
    "            col+'_etc'\n",
    "\n",
    "            \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
